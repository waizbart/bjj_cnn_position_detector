{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\native_module.py:92: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../jiu_annotations.json', 'r') as file:\n",
    "    annotations = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'standing': 0, 'takedown': 1, 'open_guard': 2, 'half_guard': 3, 'closed_guard': 4, '5050_guard': 5, 'side_control': 6, 'mount': 7, 'back': 8, 'turtle': 9}\n",
    "num_labels = len(labels)\n",
    "num_keypoints = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "data = []\n",
    "\n",
    "try:\n",
    "    for annotation in annotations:\n",
    "        label = annotation['position']\n",
    "        if label[-1].isdigit():\n",
    "            label = label[:-1]\n",
    "        \n",
    "        if annotation.get('pose1'):\n",
    "            keypoints = annotation['pose1']\n",
    "        else:\n",
    "            keypoints = annotation['pose2']\n",
    "            \n",
    "        keypoints = np.array(keypoints).astype(np.float32).reshape(num_keypoints * 3)\n",
    "        \n",
    "        max_x = max(keypoints)\n",
    "        normalized_keypoints = keypoints / max_x\n",
    "        \n",
    "        data.append((normalized_keypoints, labels[label]))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    \n",
    "keypoints_list = []\n",
    "labels_list = []\n",
    "\n",
    "shuffle(data)\n",
    "\n",
    "for keypoints, label in data:\n",
    "    keypoints_list.append(keypoints)\n",
    "    labels_list.append(label)\n",
    "    \n",
    "labels_list = np.array(labels_list)\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  96223\n",
      "Test:  24056\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PERCENTAGE = 0.8\n",
    "\n",
    "train_keypoints = keypoints_list[:int(len(keypoints_list) * TRAIN_PERCENTAGE)]\n",
    "train_labels = labels_list[:int(len(labels_list) * TRAIN_PERCENTAGE)]\n",
    "\n",
    "test_keypoints = keypoints_list[int(len(keypoints_list) * TRAIN_PERCENTAGE):]\n",
    "test_labels = labels_list[int(len(labels_list) * TRAIN_PERCENTAGE):]\n",
    "\n",
    "train_keypoints = np.array(train_keypoints)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "\n",
    "test_keypoints = np.array(test_keypoints)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "print(\"Train: \", len(train_keypoints))\n",
    "print(\"Test: \", len(test_keypoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               26624     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101194 (395.29 KB)\n",
      "Trainable params: 101194 (395.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(num_keypoints * 3,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_labels, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5991/6014 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.9376\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94338, saving model to weights.best.hdf5\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1864 - accuracy: 0.9376 - val_loss: 0.1667 - val_accuracy: 0.9434\n",
      "Epoch 2/100\n",
      " 112/6014 [..............................] - ETA: 8s - loss: 0.1842 - accuracy: 0.9286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6008/6014 [============================>.] - ETA: 0s - loss: 0.1785 - accuracy: 0.9397\n",
      "Epoch 2: val_accuracy did not improve from 0.94338\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1786 - accuracy: 0.9397 - val_loss: 0.1745 - val_accuracy: 0.9391\n",
      "Epoch 3/100\n",
      "5974/6014 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.9404\n",
      "Epoch 3: val_accuracy did not improve from 0.94338\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1762 - accuracy: 0.9405 - val_loss: 0.1778 - val_accuracy: 0.9377\n",
      "Epoch 4/100\n",
      "5996/6014 [============================>.] - ETA: 0s - loss: 0.1745 - accuracy: 0.9407\n",
      "Epoch 4: val_accuracy did not improve from 0.94338\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1743 - accuracy: 0.9407 - val_loss: 0.1731 - val_accuracy: 0.9416\n",
      "Epoch 5/100\n",
      "6001/6014 [============================>.] - ETA: 0s - loss: 0.1770 - accuracy: 0.9401\n",
      "Epoch 5: val_accuracy did not improve from 0.94338\n",
      "6014/6014 [==============================] - 9s 1ms/step - loss: 0.1768 - accuracy: 0.9402 - val_loss: 0.1885 - val_accuracy: 0.9360\n",
      "Epoch 6/100\n",
      "5990/6014 [============================>.] - ETA: 0s - loss: 0.1688 - accuracy: 0.9431\n",
      "Epoch 6: val_accuracy did not improve from 0.94338\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1688 - accuracy: 0.9431 - val_loss: 0.1764 - val_accuracy: 0.9417\n",
      "Epoch 7/100\n",
      "6013/6014 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9410\n",
      "Epoch 7: val_accuracy improved from 0.94338 to 0.94401, saving model to weights.best.hdf5\n",
      "6014/6014 [==============================] - 9s 1ms/step - loss: 0.1719 - accuracy: 0.9410 - val_loss: 0.1616 - val_accuracy: 0.9440\n",
      "Epoch 8/100\n",
      "6003/6014 [============================>.] - ETA: 0s - loss: 0.1688 - accuracy: 0.9425\n",
      "Epoch 8: val_accuracy did not improve from 0.94401\n",
      "6014/6014 [==============================] - 9s 1ms/step - loss: 0.1688 - accuracy: 0.9425 - val_loss: 0.1987 - val_accuracy: 0.9329\n",
      "Epoch 9/100\n",
      "5982/6014 [============================>.] - ETA: 0s - loss: 0.1681 - accuracy: 0.9427\n",
      "Epoch 9: val_accuracy improved from 0.94401 to 0.94525, saving model to weights.best.hdf5\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1680 - accuracy: 0.9427 - val_loss: 0.1662 - val_accuracy: 0.9453\n",
      "Epoch 10/100\n",
      "6013/6014 [============================>.] - ETA: 0s - loss: 0.1681 - accuracy: 0.9428\n",
      "Epoch 10: val_accuracy did not improve from 0.94525\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1681 - accuracy: 0.9428 - val_loss: 0.2423 - val_accuracy: 0.9184\n",
      "Epoch 11/100\n",
      "5982/6014 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9434\n",
      "Epoch 11: val_accuracy improved from 0.94525 to 0.94550, saving model to weights.best.hdf5\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1683 - accuracy: 0.9433 - val_loss: 0.1640 - val_accuracy: 0.9455\n",
      "Epoch 12/100\n",
      "5992/6014 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9438\n",
      "Epoch 12: val_accuracy did not improve from 0.94550\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1657 - accuracy: 0.9438 - val_loss: 0.1778 - val_accuracy: 0.9402\n",
      "Epoch 13/100\n",
      "5985/6014 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9442\n",
      "Epoch 13: val_accuracy did not improve from 0.94550\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1633 - accuracy: 0.9441 - val_loss: 0.2184 - val_accuracy: 0.9297\n",
      "Epoch 14/100\n",
      "5995/6014 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 0.9449\n",
      "Epoch 14: val_accuracy did not improve from 0.94550\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1628 - accuracy: 0.9448 - val_loss: 0.1729 - val_accuracy: 0.9406\n",
      "Epoch 15/100\n",
      "6008/6014 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9446\n",
      "Epoch 15: val_accuracy did not improve from 0.94550\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1616 - accuracy: 0.9446 - val_loss: 0.1740 - val_accuracy: 0.9416\n",
      "Epoch 16/100\n",
      "6004/6014 [============================>.] - ETA: 0s - loss: 0.1637 - accuracy: 0.9441\n",
      "Epoch 16: val_accuracy did not improve from 0.94550\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1636 - accuracy: 0.9442 - val_loss: 0.1940 - val_accuracy: 0.9356\n",
      "Epoch 17/100\n",
      "5989/6014 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9458\n",
      "Epoch 17: val_accuracy did not improve from 0.94550\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1593 - accuracy: 0.9458 - val_loss: 0.2059 - val_accuracy: 0.9324\n",
      "Epoch 18/100\n",
      "5997/6014 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9448\n",
      "Epoch 18: val_accuracy did not improve from 0.94550\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1594 - accuracy: 0.9448 - val_loss: 0.1848 - val_accuracy: 0.9382\n",
      "Epoch 19/100\n",
      "5996/6014 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9469\n",
      "Epoch 19: val_accuracy improved from 0.94550 to 0.95174, saving model to weights.best.hdf5\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1572 - accuracy: 0.9470 - val_loss: 0.1449 - val_accuracy: 0.9517\n",
      "Epoch 20/100\n",
      "5998/6014 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9469\n",
      "Epoch 20: val_accuracy did not improve from 0.95174\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1550 - accuracy: 0.9469 - val_loss: 0.1861 - val_accuracy: 0.9406\n",
      "Epoch 21/100\n",
      "5965/6014 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9458\n",
      "Epoch 21: val_accuracy did not improve from 0.95174\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1561 - accuracy: 0.9457 - val_loss: 0.1790 - val_accuracy: 0.9415\n",
      "Epoch 22/100\n",
      "6002/6014 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9466\n",
      "Epoch 22: val_accuracy did not improve from 0.95174\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1570 - accuracy: 0.9466 - val_loss: 0.1834 - val_accuracy: 0.9384\n",
      "Epoch 23/100\n",
      "5996/6014 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9472\n",
      "Epoch 23: val_accuracy did not improve from 0.95174\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1556 - accuracy: 0.9471 - val_loss: 0.1640 - val_accuracy: 0.9446\n",
      "Epoch 24/100\n",
      "5969/6014 [============================>.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9460\n",
      "Epoch 24: val_accuracy did not improve from 0.95174\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1587 - accuracy: 0.9460 - val_loss: 0.1536 - val_accuracy: 0.9502\n",
      "Epoch 25/100\n",
      "6006/6014 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 0.9471\n",
      "Epoch 25: val_accuracy did not improve from 0.95174\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1542 - accuracy: 0.9471 - val_loss: 0.1892 - val_accuracy: 0.9398\n",
      "Epoch 26/100\n",
      "5999/6014 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9480\n",
      "Epoch 26: val_accuracy did not improve from 0.95174\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1522 - accuracy: 0.9479 - val_loss: 0.1851 - val_accuracy: 0.9413\n",
      "Epoch 27/100\n",
      "5969/6014 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9487\n",
      "Epoch 27: val_accuracy did not improve from 0.95174\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1518 - accuracy: 0.9488 - val_loss: 0.1775 - val_accuracy: 0.9412\n",
      "Epoch 28/100\n",
      "6009/6014 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9480\n",
      "Epoch 28: val_accuracy did not improve from 0.95174\n",
      "6014/6014 [==============================] - 9s 1ms/step - loss: 0.1505 - accuracy: 0.9481 - val_loss: 0.1579 - val_accuracy: 0.9509\n",
      "Epoch 29/100\n",
      "5998/6014 [============================>.] - ETA: 0s - loss: 0.1489 - accuracy: 0.9495\n",
      "Epoch 29: val_accuracy improved from 0.95174 to 0.95190, saving model to weights.best.hdf5\n",
      "6014/6014 [==============================] - 9s 1ms/step - loss: 0.1490 - accuracy: 0.9494 - val_loss: 0.1496 - val_accuracy: 0.9519\n",
      "Epoch 30/100\n",
      "5991/6014 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9475\n",
      "Epoch 30: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1533 - accuracy: 0.9474 - val_loss: 0.1897 - val_accuracy: 0.9378\n",
      "Epoch 31/100\n",
      "5994/6014 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9491\n",
      "Epoch 31: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1509 - accuracy: 0.9490 - val_loss: 0.1903 - val_accuracy: 0.9406\n",
      "Epoch 32/100\n",
      "6002/6014 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9492\n",
      "Epoch 32: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1477 - accuracy: 0.9492 - val_loss: 0.1646 - val_accuracy: 0.9458\n",
      "Epoch 33/100\n",
      "5975/6014 [============================>.] - ETA: 0s - loss: 0.1473 - accuracy: 0.9498\n",
      "Epoch 33: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1476 - accuracy: 0.9498 - val_loss: 0.1750 - val_accuracy: 0.9429\n",
      "Epoch 34/100\n",
      "5995/6014 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9499\n",
      "Epoch 34: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1462 - accuracy: 0.9498 - val_loss: 0.1954 - val_accuracy: 0.9380\n",
      "Epoch 35/100\n",
      "6002/6014 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 0.9495\n",
      "Epoch 35: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1463 - accuracy: 0.9495 - val_loss: 0.1473 - val_accuracy: 0.9511\n",
      "Epoch 36/100\n",
      "5979/6014 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9507\n",
      "Epoch 36: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1444 - accuracy: 0.9507 - val_loss: 0.1715 - val_accuracy: 0.9453\n",
      "Epoch 37/100\n",
      "5995/6014 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9500\n",
      "Epoch 37: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1459 - accuracy: 0.9500 - val_loss: 0.1597 - val_accuracy: 0.9507\n",
      "Epoch 38/100\n",
      "5995/6014 [============================>.] - ETA: 0s - loss: 0.1468 - accuracy: 0.9507\n",
      "Epoch 38: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 9s 1ms/step - loss: 0.1467 - accuracy: 0.9507 - val_loss: 0.1859 - val_accuracy: 0.9429\n",
      "Epoch 39/100\n",
      "5984/6014 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9503\n",
      "Epoch 39: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1449 - accuracy: 0.9503 - val_loss: 0.2639 - val_accuracy: 0.9164\n",
      "Epoch 40/100\n",
      "5975/6014 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9498\n",
      "Epoch 40: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1464 - accuracy: 0.9498 - val_loss: 0.1859 - val_accuracy: 0.9397\n",
      "Epoch 41/100\n",
      "5979/6014 [============================>.] - ETA: 0s - loss: 0.1421 - accuracy: 0.9519\n",
      "Epoch 41: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1422 - accuracy: 0.9519 - val_loss: 0.1911 - val_accuracy: 0.9397\n",
      "Epoch 42/100\n",
      "5975/6014 [============================>.] - ETA: 0s - loss: 0.1429 - accuracy: 0.9520\n",
      "Epoch 42: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1426 - accuracy: 0.9520 - val_loss: 0.1566 - val_accuracy: 0.9495\n",
      "Epoch 43/100\n",
      "5984/6014 [============================>.] - ETA: 0s - loss: 0.1429 - accuracy: 0.9508\n",
      "Epoch 43: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1430 - accuracy: 0.9507 - val_loss: 0.1619 - val_accuracy: 0.9492\n",
      "Epoch 44/100\n",
      "5986/6014 [============================>.] - ETA: 0s - loss: 0.1393 - accuracy: 0.9526\n",
      "Epoch 44: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1394 - accuracy: 0.9526 - val_loss: 0.1599 - val_accuracy: 0.9492\n",
      "Epoch 45/100\n",
      "6002/6014 [============================>.] - ETA: 0s - loss: 0.1388 - accuracy: 0.9527\n",
      "Epoch 45: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1388 - accuracy: 0.9526 - val_loss: 0.2020 - val_accuracy: 0.9374\n",
      "Epoch 46/100\n",
      "5980/6014 [============================>.] - ETA: 0s - loss: 0.1395 - accuracy: 0.9527\n",
      "Epoch 46: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1396 - accuracy: 0.9527 - val_loss: 0.2217 - val_accuracy: 0.9314\n",
      "Epoch 47/100\n",
      "5973/6014 [============================>.] - ETA: 0s - loss: 0.1400 - accuracy: 0.9527\n",
      "Epoch 47: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1400 - accuracy: 0.9527 - val_loss: 0.1886 - val_accuracy: 0.9414\n",
      "Epoch 48/100\n",
      "5981/6014 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9532\n",
      "Epoch 48: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 7s 1ms/step - loss: 0.1364 - accuracy: 0.9532 - val_loss: 0.1808 - val_accuracy: 0.9457\n",
      "Epoch 49/100\n",
      "5982/6014 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9526\n",
      "Epoch 49: val_accuracy did not improve from 0.95190\n",
      "6014/6014 [==============================] - 8s 1ms/step - loss: 0.1401 - accuracy: 0.9526 - val_loss: 0.1734 - val_accuracy: 0.9456\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"weights.best.hdf5\"\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                              patience=20)\n",
    "\n",
    "history = model.fit(train_keypoints, train_labels,\n",
    "                    epochs=100,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(test_keypoints, test_labels),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_keypoints, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Utility\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "open_guard\n"
     ]
    }
   ],
   "source": [
    "# REMOVE THIS LINE TO TEST THE MODEL\n",
    "model_checkpoint = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "model_new = tf.keras.models.load_model(\"jiu_model.h5\")\n",
    "\n",
    "keypoints = np.array(annotations[10000]['pose2']).reshape(1, num_keypoints * 3)\n",
    "\n",
    "max_x = max(keypoints[0])\n",
    "normalized_keypoints = keypoints / max_x\n",
    "\n",
    "prediction = model_new.predict(normalized_keypoints)\n",
    "\n",
    "max_index = np.argmax(prediction[0])\n",
    "\n",
    "for label, index in labels.items():\n",
    "    if index == max_index:\n",
    "        print(label)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "\n",
    "model.save('jiu_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24056\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n):\n\u001b[0;32m     10\u001b[0m     test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([test_keypoints[i]])\n\u001b[1;32m---> 12\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     correct_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(test_labels[i])\n\u001b[0;32m     15\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2653\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2651\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2652\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 2653\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2654\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m   2655\u001b[0m             tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function(iterator)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1411\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1412\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1413\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1416\u001b[0m )\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    690\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    691\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:839\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \n\u001b[0;32m    832\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 839\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    821\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    822\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    823\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    825\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    826\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    807\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:535\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    534\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    538\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for each label\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "n = len(test_keypoints)\n",
    "\n",
    "print(n)\n",
    "\n",
    "for i in range(0, n):\n",
    "    test = np.array([test_keypoints[i]])\n",
    "\n",
    "    prediction = model.predict(test)\n",
    "    \n",
    "    correct_label = np.argmax(test_labels[i])\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    label_name = list(labels.keys())[predicted_label]\n",
    "    \n",
    "    if predicted_label == correct_label:\n",
    "        if label_name in test_dict:\n",
    "            test_dict[label_name][\"correct\"] += 1\n",
    "        else:\n",
    "            test_dict[label_name] = {\"correct\": 1, \"incorrect\": 0}\n",
    "    else:\n",
    "        if label_name in test_dict:\n",
    "            test_dict[label_name][\"incorrect\"] += 1\n",
    "        else:\n",
    "            test_dict[label_name] = {\"correct\": 0, \"incorrect\": 1}\n",
    "    \n",
    "for key in test_dict:\n",
    "    correct = test_dict[key][\"correct\"]\n",
    "    incorrect = test_dict[key][\"incorrect\"]\n",
    "    \n",
    "    print(f\"Accuracy for {key}: {correct / (correct + incorrect)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
