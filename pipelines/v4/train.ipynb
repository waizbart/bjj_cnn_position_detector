{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../assets/annotations.json', 'r') as file:\n",
    "    annotations = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'standing': 0, 'takedown': 1, 'open_guard': 2, 'half_guard': 3, 'closed_guard': 4, '5050_guard': 5, 'side_control': 6, 'mount': 7, 'back': 8, 'turtle': 9}\n",
    "num_labels = len(labels)\n",
    "num_keypoints = 17\n",
    "num_players = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "data = []\n",
    "\n",
    "try:\n",
    "    for annotation in annotations:\n",
    "        label = annotation['position']\n",
    "        if label[-1].isdigit():\n",
    "            label = label[:-1]\n",
    "        \n",
    "        if annotation.get('pose1'):\n",
    "            keypoints1 = [keypoint[:2] for keypoint in annotation['pose1']]\n",
    "        else:\n",
    "            keypoints1 = [[0] * 2] * num_keypoints\n",
    "            \n",
    "        if annotation.get('pose2'):\n",
    "            keypoints2 = [keypoint[:2] for keypoint in annotation['pose2']]\n",
    "        else:\n",
    "            keypoints2 = [[0] * 2] * num_keypoints\n",
    "            \n",
    "        keypoints = np.array(keypoints1 + keypoints2).astype(np.float32).reshape(num_keypoints * num_players * 2)        \n",
    "        max_x = max(keypoints)\n",
    "        normalized_keypoints = keypoints / max_x\n",
    "        data.append((normalized_keypoints, labels[label]))\n",
    "        \n",
    "        # keypoints com poses invertidas\n",
    "        inverted_keypoints = np.array(keypoints2 + keypoints1).astype(np.float32).reshape(num_keypoints * num_players * 2)        \n",
    "        max_x = max(keypoints)\n",
    "        normalized_keypoints = inverted_keypoints / max_x\n",
    "        data.append((normalized_keypoints, labels[label]))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    \n",
    "keypoints_list = []\n",
    "labels_list = []\n",
    "\n",
    "print(data)\n",
    "\n",
    "shuffle(data)\n",
    "\n",
    "for keypoints, label in data:\n",
    "    keypoints_list.append(keypoints)\n",
    "    labels_list.append(label)\n",
    "    \n",
    "labels_list = np.array(labels_list)\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  192446\n",
      "Test:  48112\n",
      "Label example:  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Keypoint example [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.9152806  0.2448178\n",
      " 0.9079395  0.22825775 0.9186173  0.2287743  0.8366856  0.2119278\n",
      " 0.91341656 0.22078535 0.7652717  0.29898068 0.9087139  0.29523975\n",
      " 0.7666144  0.4353233  0.94042003 0.4562554  0.9063411  0.4489092\n",
      " 1.         0.46783373 0.7492086  0.5439522  0.8375664  0.5368985\n",
      " 0.77531666 0.7837812  0.85116094 0.78205204 0.7588074  0.99223167\n",
      " 0.8253894  0.99223495]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PERCENTAGE = 0.8\n",
    "\n",
    "train_keypoints = keypoints_list[:int(len(keypoints_list) * TRAIN_PERCENTAGE)]\n",
    "train_labels = labels_list[:int(len(labels_list) * TRAIN_PERCENTAGE)]\n",
    "\n",
    "test_keypoints = keypoints_list[int(len(keypoints_list) * TRAIN_PERCENTAGE):]\n",
    "test_labels = labels_list[int(len(labels_list) * TRAIN_PERCENTAGE):]\n",
    "\n",
    "train_keypoints = np.array(train_keypoints)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "\n",
    "test_keypoints = np.array(test_keypoints)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "print(\"Train: \", len(train_keypoints))\n",
    "print(\"Test: \", len(test_keypoints))\n",
    "\n",
    "print(\"Label example: \", train_labels[65])\n",
    "print(\"Keypoint example\", train_keypoints[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waizbart/Documents/projects/bjj_ia/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730129740.070102   32723 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-28 12:35:40.364614: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m35,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,898</span> (429.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,898\u001b[0m (429.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,898</span> (429.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,898\u001b[0m (429.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(num_keypoints * 2 * num_players,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_labels, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m11990/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.5567 - loss: 1.2546\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74480, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 872us/step - accuracy: 0.5570 - loss: 1.2537 - val_accuracy: 0.7448 - val_loss: 0.7221\n",
      "Epoch 2/100\n",
      "\u001b[1m11985/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.7500 - loss: 0.6944\n",
      "Epoch 2: val_accuracy improved from 0.74480 to 0.78812, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 860us/step - accuracy: 0.7501 - loss: 0.6943 - val_accuracy: 0.7881 - val_loss: 0.5889\n",
      "Epoch 3/100\n",
      "\u001b[1m12016/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7938 - loss: 0.5676\n",
      "Epoch 3: val_accuracy improved from 0.78812 to 0.79340, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 871us/step - accuracy: 0.7938 - loss: 0.5676 - val_accuracy: 0.7934 - val_loss: 0.5625\n",
      "Epoch 4/100\n",
      "\u001b[1m12003/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.8247 - loss: 0.4891\n",
      "Epoch 4: val_accuracy improved from 0.79340 to 0.83954, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 890us/step - accuracy: 0.8247 - loss: 0.4890 - val_accuracy: 0.8395 - val_loss: 0.4483\n",
      "Epoch 5/100\n",
      "\u001b[1m11973/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.8415 - loss: 0.4421\n",
      "Epoch 5: val_accuracy improved from 0.83954 to 0.84530, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 862us/step - accuracy: 0.8416 - loss: 0.4421 - val_accuracy: 0.8453 - val_loss: 0.4300\n",
      "Epoch 6/100\n",
      "\u001b[1m12021/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.8555 - loss: 0.4034\n",
      "Epoch 6: val_accuracy improved from 0.84530 to 0.86810, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 856us/step - accuracy: 0.8555 - loss: 0.4034 - val_accuracy: 0.8681 - val_loss: 0.3691\n",
      "Epoch 7/100\n",
      "\u001b[1m12008/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.8675 - loss: 0.3762\n",
      "Epoch 7: val_accuracy improved from 0.86810 to 0.87920, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 854us/step - accuracy: 0.8675 - loss: 0.3761 - val_accuracy: 0.8792 - val_loss: 0.3474\n",
      "Epoch 8/100\n",
      "\u001b[1m12005/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.8757 - loss: 0.3505\n",
      "Epoch 8: val_accuracy did not improve from 0.87920\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 867us/step - accuracy: 0.8757 - loss: 0.3505 - val_accuracy: 0.8671 - val_loss: 0.3708\n",
      "Epoch 9/100\n",
      "\u001b[1m11966/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.8833 - loss: 0.3285\n",
      "Epoch 9: val_accuracy did not improve from 0.87920\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 856us/step - accuracy: 0.8833 - loss: 0.3284 - val_accuracy: 0.8775 - val_loss: 0.3532\n",
      "Epoch 10/100\n",
      "\u001b[1m12009/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.8878 - loss: 0.3197\n",
      "Epoch 10: val_accuracy improved from 0.87920 to 0.89053, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 864us/step - accuracy: 0.8878 - loss: 0.3197 - val_accuracy: 0.8905 - val_loss: 0.3093\n",
      "Epoch 11/100\n",
      "\u001b[1m12018/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.8942 - loss: 0.3017\n",
      "Epoch 11: val_accuracy did not improve from 0.89053\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 864us/step - accuracy: 0.8942 - loss: 0.3017 - val_accuracy: 0.8873 - val_loss: 0.3195\n",
      "Epoch 12/100\n",
      "\u001b[1m12015/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.8995 - loss: 0.2872\n",
      "Epoch 12: val_accuracy did not improve from 0.89053\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 892us/step - accuracy: 0.8995 - loss: 0.2872 - val_accuracy: 0.8851 - val_loss: 0.3250\n",
      "Epoch 13/100\n",
      "\u001b[1m12025/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9025 - loss: 0.2792\n",
      "Epoch 13: val_accuracy improved from 0.89053 to 0.90381, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 866us/step - accuracy: 0.9025 - loss: 0.2792 - val_accuracy: 0.9038 - val_loss: 0.2730\n",
      "Epoch 14/100\n",
      "\u001b[1m11983/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.9052 - loss: 0.2718\n",
      "Epoch 14: val_accuracy did not improve from 0.90381\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 885us/step - accuracy: 0.9052 - loss: 0.2718 - val_accuracy: 0.9007 - val_loss: 0.2957\n",
      "Epoch 15/100\n",
      "\u001b[1m11996/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9108 - loss: 0.2555\n",
      "Epoch 15: val_accuracy improved from 0.90381 to 0.90574, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 847us/step - accuracy: 0.9108 - loss: 0.2555 - val_accuracy: 0.9057 - val_loss: 0.2709\n",
      "Epoch 16/100\n",
      "\u001b[1m11988/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.9129 - loss: 0.2491\n",
      "Epoch 16: val_accuracy did not improve from 0.90574\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 833us/step - accuracy: 0.9129 - loss: 0.2491 - val_accuracy: 0.8968 - val_loss: 0.2941\n",
      "Epoch 17/100\n",
      "\u001b[1m11987/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.9150 - loss: 0.2474\n",
      "Epoch 17: val_accuracy improved from 0.90574 to 0.91867, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 833us/step - accuracy: 0.9150 - loss: 0.2474 - val_accuracy: 0.9187 - val_loss: 0.2365\n",
      "Epoch 18/100\n",
      "\u001b[1m11961/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.9177 - loss: 0.2364\n",
      "Epoch 18: val_accuracy did not improve from 0.91867\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 835us/step - accuracy: 0.9177 - loss: 0.2364 - val_accuracy: 0.9141 - val_loss: 0.2508\n",
      "Epoch 19/100\n",
      "\u001b[1m12023/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9215 - loss: 0.2255\n",
      "Epoch 19: val_accuracy improved from 0.91867 to 0.92287, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 832us/step - accuracy: 0.9215 - loss: 0.2255 - val_accuracy: 0.9229 - val_loss: 0.2251\n",
      "Epoch 20/100\n",
      "\u001b[1m11971/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9218 - loss: 0.2267\n",
      "Epoch 20: val_accuracy did not improve from 0.92287\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 834us/step - accuracy: 0.9218 - loss: 0.2267 - val_accuracy: 0.9221 - val_loss: 0.2303\n",
      "Epoch 21/100\n",
      "\u001b[1m11983/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.9238 - loss: 0.2192\n",
      "Epoch 21: val_accuracy did not improve from 0.92287\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 834us/step - accuracy: 0.9238 - loss: 0.2192 - val_accuracy: 0.9185 - val_loss: 0.2431\n",
      "Epoch 22/100\n",
      "\u001b[1m11978/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.9255 - loss: 0.2139\n",
      "Epoch 22: val_accuracy improved from 0.92287 to 0.92339, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 842us/step - accuracy: 0.9255 - loss: 0.2139 - val_accuracy: 0.9234 - val_loss: 0.2262\n",
      "Epoch 23/100\n",
      "\u001b[1m11999/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9275 - loss: 0.2097\n",
      "Epoch 23: val_accuracy did not improve from 0.92339\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 877us/step - accuracy: 0.9275 - loss: 0.2097 - val_accuracy: 0.9186 - val_loss: 0.2405\n",
      "Epoch 24/100\n",
      "\u001b[1m12001/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9306 - loss: 0.2022\n",
      "Epoch 24: val_accuracy improved from 0.92339 to 0.93079, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 938us/step - accuracy: 0.9306 - loss: 0.2022 - val_accuracy: 0.9308 - val_loss: 0.2063\n",
      "Epoch 25/100\n",
      "\u001b[1m11978/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9300 - loss: 0.2032\n",
      "Epoch 25: val_accuracy improved from 0.93079 to 0.93214, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 866us/step - accuracy: 0.9300 - loss: 0.2032 - val_accuracy: 0.9321 - val_loss: 0.2068\n",
      "Epoch 26/100\n",
      "\u001b[1m12023/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9319 - loss: 0.1953\n",
      "Epoch 26: val_accuracy improved from 0.93214 to 0.93526, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 874us/step - accuracy: 0.9319 - loss: 0.1953 - val_accuracy: 0.9353 - val_loss: 0.1968\n",
      "Epoch 27/100\n",
      "\u001b[1m11981/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.9332 - loss: 0.1925\n",
      "Epoch 27: val_accuracy did not improve from 0.93526\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 855us/step - accuracy: 0.9332 - loss: 0.1925 - val_accuracy: 0.9291 - val_loss: 0.2133\n",
      "Epoch 28/100\n",
      "\u001b[1m11971/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.9337 - loss: 0.1915\n",
      "Epoch 28: val_accuracy did not improve from 0.93526\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 855us/step - accuracy: 0.9337 - loss: 0.1915 - val_accuracy: 0.9279 - val_loss: 0.2123\n",
      "Epoch 29/100\n",
      "\u001b[1m11964/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9349 - loss: 0.1882\n",
      "Epoch 29: val_accuracy did not improve from 0.93526\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 926us/step - accuracy: 0.9349 - loss: 0.1882 - val_accuracy: 0.9259 - val_loss: 0.2141\n",
      "Epoch 30/100\n",
      "\u001b[1m11982/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9385 - loss: 0.1815\n",
      "Epoch 30: val_accuracy did not improve from 0.93526\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 951us/step - accuracy: 0.9385 - loss: 0.1815 - val_accuracy: 0.9189 - val_loss: 0.2439\n",
      "Epoch 31/100\n",
      "\u001b[1m11978/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9384 - loss: 0.1794\n",
      "Epoch 31: val_accuracy improved from 0.93526 to 0.93991, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 905us/step - accuracy: 0.9384 - loss: 0.1794 - val_accuracy: 0.9399 - val_loss: 0.1840\n",
      "Epoch 32/100\n",
      "\u001b[1m11996/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9380 - loss: 0.1797\n",
      "Epoch 32: val_accuracy did not improve from 0.93991\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 905us/step - accuracy: 0.9380 - loss: 0.1797 - val_accuracy: 0.9385 - val_loss: 0.1951\n",
      "Epoch 33/100\n",
      "\u001b[1m12020/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9403 - loss: 0.1771\n",
      "Epoch 33: val_accuracy improved from 0.93991 to 0.94567, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 894us/step - accuracy: 0.9403 - loss: 0.1771 - val_accuracy: 0.9457 - val_loss: 0.1619\n",
      "Epoch 34/100\n",
      "\u001b[1m11990/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9417 - loss: 0.1704\n",
      "Epoch 34: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 868us/step - accuracy: 0.9417 - loss: 0.1704 - val_accuracy: 0.9351 - val_loss: 0.1964\n",
      "Epoch 35/100\n",
      "\u001b[1m11980/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9423 - loss: 0.1666\n",
      "Epoch 35: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 944us/step - accuracy: 0.9423 - loss: 0.1666 - val_accuracy: 0.9350 - val_loss: 0.1959\n",
      "Epoch 36/100\n",
      "\u001b[1m11998/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9417 - loss: 0.1697\n",
      "Epoch 36: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.1697 - val_accuracy: 0.9396 - val_loss: 0.1795\n",
      "Epoch 37/100\n",
      "\u001b[1m11990/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9448 - loss: 0.1612\n",
      "Epoch 37: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1612 - val_accuracy: 0.9348 - val_loss: 0.1988\n",
      "Epoch 38/100\n",
      "\u001b[1m11989/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9428 - loss: 0.1677\n",
      "Epoch 38: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 962us/step - accuracy: 0.9428 - loss: 0.1677 - val_accuracy: 0.9410 - val_loss: 0.1782\n",
      "Epoch 39/100\n",
      "\u001b[1m11975/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9457 - loss: 0.1586\n",
      "Epoch 39: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 907us/step - accuracy: 0.9457 - loss: 0.1586 - val_accuracy: 0.9360 - val_loss: 0.1919\n",
      "Epoch 40/100\n",
      "\u001b[1m12004/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9448 - loss: 0.1612\n",
      "Epoch 40: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 905us/step - accuracy: 0.9448 - loss: 0.1612 - val_accuracy: 0.9348 - val_loss: 0.2005\n",
      "Epoch 41/100\n",
      "\u001b[1m11984/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9458 - loss: 0.1586\n",
      "Epoch 41: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 862us/step - accuracy: 0.9458 - loss: 0.1586 - val_accuracy: 0.9364 - val_loss: 0.1949\n",
      "Epoch 42/100\n",
      "\u001b[1m11974/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9468 - loss: 0.1561\n",
      "Epoch 42: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 865us/step - accuracy: 0.9468 - loss: 0.1561 - val_accuracy: 0.9409 - val_loss: 0.1810\n",
      "Epoch 43/100\n",
      "\u001b[1m12024/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.9474 - loss: 0.1558\n",
      "Epoch 43: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 868us/step - accuracy: 0.9474 - loss: 0.1558 - val_accuracy: 0.9416 - val_loss: 0.1803\n",
      "Epoch 44/100\n",
      "\u001b[1m11985/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.9475 - loss: 0.1523\n",
      "Epoch 44: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 885us/step - accuracy: 0.9475 - loss: 0.1523 - val_accuracy: 0.9455 - val_loss: 0.1663\n",
      "Epoch 45/100\n",
      "\u001b[1m11995/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9480 - loss: 0.1506\n",
      "Epoch 45: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 868us/step - accuracy: 0.9480 - loss: 0.1506 - val_accuracy: 0.9428 - val_loss: 0.1762\n",
      "Epoch 46/100\n",
      "\u001b[1m12000/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.9493 - loss: 0.1498\n",
      "Epoch 46: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 884us/step - accuracy: 0.9493 - loss: 0.1498 - val_accuracy: 0.9421 - val_loss: 0.1832\n",
      "Epoch 47/100\n",
      "\u001b[1m12003/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.9496 - loss: 0.1467\n",
      "Epoch 47: val_accuracy did not improve from 0.94567\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 864us/step - accuracy: 0.9496 - loss: 0.1467 - val_accuracy: 0.9308 - val_loss: 0.2136\n",
      "Epoch 48/100\n",
      "\u001b[1m12019/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9497 - loss: 0.1465\n",
      "Epoch 48: val_accuracy improved from 0.94567 to 0.95342, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 899us/step - accuracy: 0.9497 - loss: 0.1465 - val_accuracy: 0.9534 - val_loss: 0.1447\n",
      "Epoch 49/100\n",
      "\u001b[1m11966/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.9509 - loss: 0.1428\n",
      "Epoch 49: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 912us/step - accuracy: 0.9509 - loss: 0.1428 - val_accuracy: 0.9353 - val_loss: 0.2060\n",
      "Epoch 50/100\n",
      "\u001b[1m12025/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9499 - loss: 0.1442\n",
      "Epoch 50: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 861us/step - accuracy: 0.9499 - loss: 0.1442 - val_accuracy: 0.9448 - val_loss: 0.1707\n",
      "Epoch 51/100\n",
      "\u001b[1m12010/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9520 - loss: 0.1417\n",
      "Epoch 51: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 871us/step - accuracy: 0.9520 - loss: 0.1417 - val_accuracy: 0.9407 - val_loss: 0.1817\n",
      "Epoch 52/100\n",
      "\u001b[1m12004/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9519 - loss: 0.1420\n",
      "Epoch 52: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 844us/step - accuracy: 0.9519 - loss: 0.1420 - val_accuracy: 0.9313 - val_loss: 0.2231\n",
      "Epoch 53/100\n",
      "\u001b[1m12006/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9517 - loss: 0.1421\n",
      "Epoch 53: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 870us/step - accuracy: 0.9517 - loss: 0.1421 - val_accuracy: 0.9525 - val_loss: 0.1504\n",
      "Epoch 54/100\n",
      "\u001b[1m11986/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.9537 - loss: 0.1366\n",
      "Epoch 54: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 898us/step - accuracy: 0.9537 - loss: 0.1367 - val_accuracy: 0.9517 - val_loss: 0.1545\n",
      "Epoch 55/100\n",
      "\u001b[1m12021/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.9525 - loss: 0.1396\n",
      "Epoch 55: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 853us/step - accuracy: 0.9525 - loss: 0.1396 - val_accuracy: 0.9527 - val_loss: 0.1504\n",
      "Epoch 56/100\n",
      "\u001b[1m11974/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.9538 - loss: 0.1378\n",
      "Epoch 56: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 926us/step - accuracy: 0.9538 - loss: 0.1378 - val_accuracy: 0.9484 - val_loss: 0.1623\n",
      "Epoch 57/100\n",
      "\u001b[1m12022/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9559 - loss: 0.1302\n",
      "Epoch 57: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 949us/step - accuracy: 0.9559 - loss: 0.1302 - val_accuracy: 0.9487 - val_loss: 0.1629\n",
      "Epoch 58/100\n",
      "\u001b[1m12021/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.9545 - loss: 0.1358\n",
      "Epoch 58: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 908us/step - accuracy: 0.9545 - loss: 0.1358 - val_accuracy: 0.9531 - val_loss: 0.1469\n",
      "Epoch 59/100\n",
      "\u001b[1m11977/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.9558 - loss: 0.1316\n",
      "Epoch 59: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 904us/step - accuracy: 0.9558 - loss: 0.1316 - val_accuracy: 0.9505 - val_loss: 0.1572\n",
      "Epoch 60/100\n",
      "\u001b[1m11984/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9543 - loss: 0.1349\n",
      "Epoch 60: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 877us/step - accuracy: 0.9543 - loss: 0.1349 - val_accuracy: 0.9499 - val_loss: 0.1567\n",
      "Epoch 61/100\n",
      "\u001b[1m12015/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.9554 - loss: 0.1308\n",
      "Epoch 61: val_accuracy did not improve from 0.95342\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 856us/step - accuracy: 0.9554 - loss: 0.1308 - val_accuracy: 0.9490 - val_loss: 0.1648\n",
      "Epoch 62/100\n",
      "\u001b[1m11974/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9554 - loss: 0.1318\n",
      "Epoch 62: val_accuracy improved from 0.95342 to 0.95533, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 876us/step - accuracy: 0.9554 - loss: 0.1318 - val_accuracy: 0.9553 - val_loss: 0.1418\n",
      "Epoch 63/100\n",
      "\u001b[1m12026/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.9563 - loss: 0.1295\n",
      "Epoch 63: val_accuracy did not improve from 0.95533\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 891us/step - accuracy: 0.9563 - loss: 0.1295 - val_accuracy: 0.9504 - val_loss: 0.1571\n",
      "Epoch 64/100\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9563 - loss: 0.1305\n",
      "Epoch 64: val_accuracy did not improve from 0.95533\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 880us/step - accuracy: 0.9563 - loss: 0.1305 - val_accuracy: 0.9492 - val_loss: 0.1644\n",
      "Epoch 65/100\n",
      "\u001b[1m12020/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9570 - loss: 0.1288\n",
      "Epoch 65: val_accuracy improved from 0.95533 to 0.95658, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 878us/step - accuracy: 0.9570 - loss: 0.1288 - val_accuracy: 0.9566 - val_loss: 0.1384\n",
      "Epoch 66/100\n",
      "\u001b[1m12018/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9572 - loss: 0.1271\n",
      "Epoch 66: val_accuracy did not improve from 0.95658\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 866us/step - accuracy: 0.9572 - loss: 0.1271 - val_accuracy: 0.9530 - val_loss: 0.1543\n",
      "Epoch 67/100\n",
      "\u001b[1m12005/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9573 - loss: 0.1249\n",
      "Epoch 67: val_accuracy did not improve from 0.95658\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 887us/step - accuracy: 0.9573 - loss: 0.1249 - val_accuracy: 0.9561 - val_loss: 0.1409\n",
      "Epoch 68/100\n",
      "\u001b[1m11990/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.9578 - loss: 0.1245\n",
      "Epoch 68: val_accuracy improved from 0.95658 to 0.95849, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 863us/step - accuracy: 0.9578 - loss: 0.1245 - val_accuracy: 0.9585 - val_loss: 0.1358\n",
      "Epoch 69/100\n",
      "\u001b[1m12018/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.9593 - loss: 0.1204\n",
      "Epoch 69: val_accuracy did not improve from 0.95849\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 868us/step - accuracy: 0.9593 - loss: 0.1204 - val_accuracy: 0.9506 - val_loss: 0.1652\n",
      "Epoch 70/100\n",
      "\u001b[1m11998/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9587 - loss: 0.1221\n",
      "Epoch 70: val_accuracy did not improve from 0.95849\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 872us/step - accuracy: 0.9587 - loss: 0.1221 - val_accuracy: 0.9571 - val_loss: 0.1402\n",
      "Epoch 71/100\n",
      "\u001b[1m11973/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.9601 - loss: 0.1201\n",
      "Epoch 71: val_accuracy did not improve from 0.95849\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 866us/step - accuracy: 0.9601 - loss: 0.1201 - val_accuracy: 0.9440 - val_loss: 0.1895\n",
      "Epoch 72/100\n",
      "\u001b[1m12017/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9591 - loss: 0.1217\n",
      "Epoch 72: val_accuracy did not improve from 0.95849\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 873us/step - accuracy: 0.9591 - loss: 0.1217 - val_accuracy: 0.9568 - val_loss: 0.1429\n",
      "Epoch 73/100\n",
      "\u001b[1m11976/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9585 - loss: 0.1229\n",
      "Epoch 73: val_accuracy did not improve from 0.95849\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 867us/step - accuracy: 0.9585 - loss: 0.1229 - val_accuracy: 0.9466 - val_loss: 0.1702\n",
      "Epoch 74/100\n",
      "\u001b[1m12023/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9604 - loss: 0.1186\n",
      "Epoch 74: val_accuracy improved from 0.95849 to 0.96157, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 862us/step - accuracy: 0.9604 - loss: 0.1186 - val_accuracy: 0.9616 - val_loss: 0.1268\n",
      "Epoch 75/100\n",
      "\u001b[1m11994/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.9605 - loss: 0.1172\n",
      "Epoch 75: val_accuracy did not improve from 0.96157\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 885us/step - accuracy: 0.9605 - loss: 0.1172 - val_accuracy: 0.9525 - val_loss: 0.1568\n",
      "Epoch 76/100\n",
      "\u001b[1m12022/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9598 - loss: 0.1181\n",
      "Epoch 76: val_accuracy did not improve from 0.96157\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 860us/step - accuracy: 0.9598 - loss: 0.1181 - val_accuracy: 0.9525 - val_loss: 0.1560\n",
      "Epoch 77/100\n",
      "\u001b[1m11991/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.9617 - loss: 0.1136\n",
      "Epoch 77: val_accuracy did not improve from 0.96157\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 862us/step - accuracy: 0.9616 - loss: 0.1136 - val_accuracy: 0.9589 - val_loss: 0.1305\n",
      "Epoch 78/100\n",
      "\u001b[1m12009/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9618 - loss: 0.1141\n",
      "Epoch 78: val_accuracy did not improve from 0.96157\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 866us/step - accuracy: 0.9618 - loss: 0.1142 - val_accuracy: 0.9572 - val_loss: 0.1396\n",
      "Epoch 79/100\n",
      "\u001b[1m11991/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9607 - loss: 0.1169\n",
      "Epoch 79: val_accuracy did not improve from 0.96157\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 849us/step - accuracy: 0.9607 - loss: 0.1169 - val_accuracy: 0.9509 - val_loss: 0.1612\n",
      "Epoch 80/100\n",
      "\u001b[1m11961/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9621 - loss: 0.1130\n",
      "Epoch 80: val_accuracy improved from 0.96157 to 0.96371, saving model to weights.best.keras\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 848us/step - accuracy: 0.9621 - loss: 0.1130 - val_accuracy: 0.9637 - val_loss: 0.1238\n",
      "Epoch 81/100\n",
      "\u001b[1m11972/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.9626 - loss: 0.1104\n",
      "Epoch 81: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 866us/step - accuracy: 0.9626 - loss: 0.1104 - val_accuracy: 0.9582 - val_loss: 0.1363\n",
      "Epoch 82/100\n",
      "\u001b[1m11964/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.9618 - loss: 0.1139\n",
      "Epoch 82: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 868us/step - accuracy: 0.9618 - loss: 0.1140 - val_accuracy: 0.9597 - val_loss: 0.1340\n",
      "Epoch 83/100\n",
      "\u001b[1m12011/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.9620 - loss: 0.1131\n",
      "Epoch 83: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 870us/step - accuracy: 0.9620 - loss: 0.1131 - val_accuracy: 0.9542 - val_loss: 0.1471\n",
      "Epoch 84/100\n",
      "\u001b[1m12004/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.9621 - loss: 0.1129\n",
      "Epoch 84: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 887us/step - accuracy: 0.9621 - loss: 0.1129 - val_accuracy: 0.9578 - val_loss: 0.1381\n",
      "Epoch 85/100\n",
      "\u001b[1m12025/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.9621 - loss: 0.1153\n",
      "Epoch 85: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 888us/step - accuracy: 0.9621 - loss: 0.1153 - val_accuracy: 0.9485 - val_loss: 0.1720\n",
      "Epoch 86/100\n",
      "\u001b[1m11963/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9625 - loss: 0.1106\n",
      "Epoch 86: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 860us/step - accuracy: 0.9625 - loss: 0.1106 - val_accuracy: 0.9471 - val_loss: 0.1742\n",
      "Epoch 87/100\n",
      "\u001b[1m11981/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9627 - loss: 0.1113\n",
      "Epoch 87: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 861us/step - accuracy: 0.9627 - loss: 0.1113 - val_accuracy: 0.9540 - val_loss: 0.1548\n",
      "Epoch 88/100\n",
      "\u001b[1m12002/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.9626 - loss: 0.1135\n",
      "Epoch 88: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 864us/step - accuracy: 0.9626 - loss: 0.1134 - val_accuracy: 0.9581 - val_loss: 0.1363\n",
      "Epoch 89/100\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9626 - loss: 0.1118\n",
      "Epoch 89: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 891us/step - accuracy: 0.9626 - loss: 0.1118 - val_accuracy: 0.9547 - val_loss: 0.1496\n",
      "Epoch 90/100\n",
      "\u001b[1m11975/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9636 - loss: 0.1099\n",
      "Epoch 90: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 866us/step - accuracy: 0.9636 - loss: 0.1099 - val_accuracy: 0.9578 - val_loss: 0.1437\n",
      "Epoch 91/100\n",
      "\u001b[1m12012/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9642 - loss: 0.1071\n",
      "Epoch 91: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 879us/step - accuracy: 0.9642 - loss: 0.1071 - val_accuracy: 0.9581 - val_loss: 0.1463\n",
      "Epoch 92/100\n",
      "\u001b[1m11970/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9638 - loss: 0.1075\n",
      "Epoch 92: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 861us/step - accuracy: 0.9638 - loss: 0.1075 - val_accuracy: 0.9593 - val_loss: 0.1313\n",
      "Epoch 93/100\n",
      "\u001b[1m12015/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9636 - loss: 0.1087\n",
      "Epoch 93: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 868us/step - accuracy: 0.9636 - loss: 0.1087 - val_accuracy: 0.9562 - val_loss: 0.1455\n",
      "Epoch 94/100\n",
      "\u001b[1m12017/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9640 - loss: 0.1089\n",
      "Epoch 94: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 896us/step - accuracy: 0.9640 - loss: 0.1089 - val_accuracy: 0.9624 - val_loss: 0.1269\n",
      "Epoch 95/100\n",
      "\u001b[1m11996/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9647 - loss: 0.1075\n",
      "Epoch 95: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 873us/step - accuracy: 0.9647 - loss: 0.1075 - val_accuracy: 0.9634 - val_loss: 0.1189\n",
      "Epoch 96/100\n",
      "\u001b[1m12022/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9644 - loss: 0.1057\n",
      "Epoch 96: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 873us/step - accuracy: 0.9644 - loss: 0.1057 - val_accuracy: 0.9625 - val_loss: 0.1224\n",
      "Epoch 97/100\n",
      "\u001b[1m11986/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.9641 - loss: 0.1068\n",
      "Epoch 97: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 891us/step - accuracy: 0.9641 - loss: 0.1068 - val_accuracy: 0.9610 - val_loss: 0.1384\n",
      "Epoch 98/100\n",
      "\u001b[1m11985/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9648 - loss: 0.1050\n",
      "Epoch 98: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 869us/step - accuracy: 0.9648 - loss: 0.1050 - val_accuracy: 0.9579 - val_loss: 0.1408\n",
      "Epoch 99/100\n",
      "\u001b[1m12003/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9663 - loss: 0.1011\n",
      "Epoch 99: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 880us/step - accuracy: 0.9663 - loss: 0.1011 - val_accuracy: 0.9628 - val_loss: 0.1248\n",
      "Epoch 100/100\n",
      "\u001b[1m12008/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9653 - loss: 0.1040\n",
      "Epoch 100: val_accuracy did not improve from 0.96371\n",
      "\u001b[1m12028/12028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 867us/step - accuracy: 0.9653 - loss: 0.1040 - val_accuracy: 0.9525 - val_loss: 0.1676\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"weights.best.keras\"\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                              patience=20)\n",
    "\n",
    "history = model.fit(train_keypoints, train_labels,\n",
    "                    epochs=100,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(test_keypoints, test_labels),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_keypoints, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Utility\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "keypoints = np.array(annotations[0]['pose2'])\n",
    "\n",
    "keypoints = [[0] * 2] * num_keypoints\n",
    "keypoints += [keypoint[:2] for keypoint in keypoints]\n",
    "\n",
    "keypoints = np.array(keypoints).astype(np.float32).reshape(num_keypoints * num_players * 2)\n",
    "\n",
    "print(keypoints.shape)\n",
    "\n",
    "max_x = max(keypoints)\n",
    "normalized_keypoints = keypoints / max_x\n",
    "\n",
    "prediction = model.predict(normalized_keypoints.reshape(1, num_keypoints * 2 * num_players))\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "max_index = np.argmax(prediction[0])\n",
    "\n",
    "for label, index in labels.items():\n",
    "    if index == max_index:\n",
    "        print(label)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for each label\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "n = len(test_keypoints)\n",
    "\n",
    "print(n)\n",
    "\n",
    "for i in range(0, n):\n",
    "    test = np.array([test_keypoints[i]])\n",
    "\n",
    "    prediction = model.predict(test)\n",
    "    \n",
    "    correct_label = np.argmax(test_labels[i])\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    label_name = list(labels.keys())[predicted_label]\n",
    "    \n",
    "    if predicted_label == correct_label:\n",
    "        if label_name in test_dict:\n",
    "            test_dict[label_name][\"correct\"] += 1\n",
    "        else:\n",
    "            test_dict[label_name] = {\"correct\": 1, \"incorrect\": 0}\n",
    "    else:\n",
    "        if label_name in test_dict:\n",
    "            test_dict[label_name][\"incorrect\"] += 1\n",
    "        else:\n",
    "            test_dict[label_name] = {\"correct\": 0, \"incorrect\": 1}\n",
    "    \n",
    "for key in test_dict:\n",
    "    correct = test_dict[key][\"correct\"]\n",
    "    incorrect = test_dict[key][\"incorrect\"]\n",
    "    \n",
    "    print(f\"Accuracy for {key}: {correct / (correct + incorrect)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
