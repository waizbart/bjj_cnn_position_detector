{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../assets/annotations.json', 'r') as file:\n",
    "    annotations = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'standing': 0, 'takedown': 1, 'open_guard': 2, 'half_guard': 3, 'closed_guard': 4, '5050_guard': 5, 'side_control': 6, 'mount': 7, 'back': 8, 'turtle': 9}\n",
    "num_labels = len(labels)\n",
    "num_keypoints = 17\n",
    "num_players = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import math\n",
    "\n",
    "def translate_keypoints(keypoints, dx, dy):\n",
    "    return [(x + dx, y + dy) for x, y in keypoints]\n",
    "\n",
    "def scale_keypoints(keypoints, scale):\n",
    "    return [(x * scale, y * scale) for x, y in keypoints]\n",
    "\n",
    "def rotate_keypoints(keypoints, angle, center):\n",
    "    angle_rad = math.radians(angle)\n",
    "    cos_theta, sin_theta = math.cos(angle_rad), math.sin(angle_rad)\n",
    "    cx, cy = center\n",
    "    return [\n",
    "        (\n",
    "            cos_theta * (x - cx) - sin_theta * (y - cy) + cx,\n",
    "            sin_theta * (x - cx) + cos_theta * (y - cy) + cy\n",
    "        )\n",
    "        for x, y in keypoints\n",
    "    ]\n",
    "\n",
    "def flip_keypoints(keypoints, image_width):\n",
    "    return [(image_width - x, y) for x, y in keypoints]\n",
    "\n",
    "def add_noise(keypoints, noise_level):\n",
    "    return [(x + np.random.normal(0, noise_level), y + np.random.normal(0, noise_level)) for x, y in keypoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m ys \u001b[38;5;241m=\u001b[39m [y \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m original_keypoints]\n\u001b[1;32m     52\u001b[0m center \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(xs), np\u001b[38;5;241m.\u001b[39mmean(ys))\n\u001b[0;32m---> 53\u001b[0m rotated_keypoints \u001b[38;5;241m=\u001b[39m \u001b[43mrotate_keypoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_keypoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m augmentations\u001b[38;5;241m.\u001b[39mappend(rotated_keypoints)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# 4. Horizontal Flip\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36mrotate_keypoints\u001b[0;34m(keypoints, angle, center)\u001b[0m\n\u001b[1;32m     13\u001b[0m cos_theta, sin_theta \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(angle_rad), math\u001b[38;5;241m.\u001b[39msin(angle_rad)\n\u001b[1;32m     14\u001b[0m cx, cy \u001b[38;5;241m=\u001b[39m center\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     16\u001b[0m     (\n\u001b[1;32m     17\u001b[0m         cos_theta \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m-\u001b[39m cx) \u001b[38;5;241m-\u001b[39m sin_theta \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m-\u001b[39m cy) \u001b[38;5;241m+\u001b[39m cx,\n\u001b[1;32m     18\u001b[0m         sin_theta \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m-\u001b[39m cx) \u001b[38;5;241m+\u001b[39m cos_theta \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m-\u001b[39m cy) \u001b[38;5;241m+\u001b[39m cy\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m keypoints\n\u001b[1;32m     21\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m cos_theta, sin_theta \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(angle_rad), math\u001b[38;5;241m.\u001b[39msin(angle_rad)\n\u001b[1;32m     14\u001b[0m cx, cy \u001b[38;5;241m=\u001b[39m center\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     16\u001b[0m     (\n\u001b[1;32m     17\u001b[0m         cos_theta \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m-\u001b[39m cx) \u001b[38;5;241m-\u001b[39m sin_theta \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m-\u001b[39m cy) \u001b[38;5;241m+\u001b[39m cx,\n\u001b[1;32m     18\u001b[0m         sin_theta \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m-\u001b[39m cx) \u001b[38;5;241m+\u001b[39m cos_theta \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m-\u001b[39m cy) \u001b[38;5;241m+\u001b[39m cy\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m keypoints\n\u001b[1;32m     21\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "data = []\n",
    "\n",
    "try:\n",
    "    for annotation in annotations:\n",
    "        label = annotation['position']\n",
    "        if label[-1].isdigit():\n",
    "            label = label[:-1]\n",
    "        \n",
    "        if annotation.get('pose1'):\n",
    "            keypoints1 = [keypoint[:2] for keypoint in annotation['pose1']]\n",
    "        else:\n",
    "            keypoints1 = [[0] * 2] * num_keypoints\n",
    "            \n",
    "        if annotation.get('pose2'):\n",
    "            keypoints2 = [keypoint[:2] for keypoint in annotation['pose2']]\n",
    "        else:\n",
    "            keypoints2 = [[0] * 2] * num_keypoints\n",
    "\n",
    "        # keypoints originais\n",
    "        original_keypoints = keypoints1 + keypoints2\n",
    "        keypoints_array = np.array(original_keypoints).astype(np.float32).reshape(num_keypoints * num_players * 2)\n",
    "        max_x = max(keypoints_array)\n",
    "        normalized_keypoints = keypoints_array / max_x\n",
    "        data.append((normalized_keypoints, labels[label]))\n",
    "        \n",
    "        # keypoints com poses invertidas \n",
    "        inverted_keypoints = keypoints2 + keypoints1\n",
    "        inverted_keypoints_array = np.array(inverted_keypoints).astype(np.float32).reshape(num_keypoints * num_players * 2)\n",
    "        max_x = max(inverted_keypoints_array)\n",
    "        normalized_inverted_keypoints = inverted_keypoints_array / max_x\n",
    "        data.append((normalized_inverted_keypoints, labels[label]))\n",
    "\n",
    "        for keypoints in [original_keypoints, inverted_keypoints]:\n",
    "            augmentations = []\n",
    "            \n",
    "            # 1. Translation\n",
    "            dx, dy = np.random.randint(-20, 20), np.random.randint(-20, 20)\n",
    "            translated_keypoints = translate_keypoints(original_keypoints, dx, dy)\n",
    "            augmentations.append(translated_keypoints)\n",
    "\n",
    "            # 2. Scaling\n",
    "            scale_factor = np.random.uniform(0.8, 1.2)\n",
    "            scaled_keypoints = scale_keypoints(original_keypoints, scale_factor)\n",
    "            augmentations.append(scaled_keypoints)\n",
    "\n",
    "            # 3. Rotation\n",
    "            angle = np.random.uniform(-30, 30)\n",
    "            xs = [x for x, y in original_keypoints]\n",
    "            ys = [y for x, y in original_keypoints]\n",
    "            center = (np.mean(xs), np.mean(ys))\n",
    "            rotated_keypoints = rotate_keypoints(original_keypoints, angle, center)\n",
    "            augmentations.append(rotated_keypoints)\n",
    "\n",
    "            # 4. Horizontal Flip\n",
    "            image_width = max(xs)  \n",
    "            flipped_keypoints = flip_keypoints(original_keypoints, image_width)\n",
    "            augmentations.append(flipped_keypoints)\n",
    "\n",
    "            # 5. Add Noise\n",
    "            noisy_keypoints = add_noise(original_keypoints, noise_level=2)\n",
    "            augmentations.append(noisy_keypoints)\n",
    "\n",
    "            for aug_keypoints in augmentations:\n",
    "                aug_keypoints_array = np.array(aug_keypoints).astype(np.float32).reshape(num_keypoints * num_players * 2)\n",
    "                max_x = max(aug_keypoints_array)\n",
    "                normalized_aug_keypoints = aug_keypoints_array / max_x\n",
    "                data.append((normalized_aug_keypoints, labels[label]))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "keypoints_list = []\n",
    "labels_list = []\n",
    "\n",
    "shuffle(data)\n",
    "\n",
    "for keypoints, label in data:\n",
    "    keypoints_list.append(keypoints)\n",
    "    labels_list.append(label)\n",
    "\n",
    "labels_list = np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1154678\n",
      "Test:  288670\n",
      "Label example:  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Keypoint example [0.46629515 0.2835518  0.46101752 0.2722335  0.45167482 0.27768376\n",
      " 0.4408722  0.27735952 0.41895014 0.2947803  0.47754714 0.30245635\n",
      " 0.39398727 0.35766214 0.5361657  0.29786906 0.3822555  0.44908518\n",
      " 0.6006186  0.29692796 0.40021443 0.5270957  0.4922452  0.42654905\n",
      " 0.46207696 0.4825509  0.56597906 0.33319393 0.5046792  0.434746\n",
      " 0.64070773 0.42629018 0.6005842  0.4570997  0.88205075 0.20180856\n",
      " 0.87821513 0.19232537 0.8910183  0.19565324 0.86784285 0.18635692\n",
      " 0.8994012  0.19425465 0.82073575 0.16865113 0.9165882  0.18104266\n",
      " 0.7268421  0.16230437 0.9504453  0.26144308 0.7183461  0.23151894\n",
      " 1.         0.3414818  0.72160345 0.1800137  0.7908244  0.19203483\n",
      " 0.7661923  0.28955936 0.8876098  0.30109596 0.77565306 0.39810595\n",
      " 0.76628655 0.35276145]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PERCENTAGE = 0.8\n",
    "\n",
    "train_keypoints = keypoints_list[:int(len(keypoints_list) * TRAIN_PERCENTAGE)]\n",
    "train_labels = labels_list[:int(len(labels_list) * TRAIN_PERCENTAGE)]\n",
    "\n",
    "test_keypoints = keypoints_list[int(len(keypoints_list) * TRAIN_PERCENTAGE):]\n",
    "test_labels = labels_list[int(len(labels_list) * TRAIN_PERCENTAGE):]\n",
    "\n",
    "train_keypoints = np.array(train_keypoints)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "\n",
    "test_keypoints = np.array(test_keypoints)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "print(\"Train: \", len(train_keypoints))\n",
    "print(\"Test: \", len(test_keypoints))\n",
    "\n",
    "print(\"Label example: \", train_labels[65])\n",
    "print(\"Keypoint example\", train_keypoints[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waizbart/Documents/projects/bjj_ia/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730131387.213517   39256 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-28 13:03:07.245876: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m35,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,898</span> (429.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,898\u001b[0m (429.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,898</span> (429.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,898\u001b[0m (429.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(num_keypoints * 2 * num_players,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_labels, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 13:03:40.047488: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 314072416 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72102/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7053 - loss: 0.8337\n",
      "Epoch 1: val_accuracy improved from -inf to 0.84901, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 846us/step - accuracy: 0.7054 - loss: 0.8335 - val_accuracy: 0.8490 - val_loss: 0.4299\n",
      "Epoch 2/100\n",
      "\u001b[1m72129/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.8561 - loss: 0.4099\n",
      "Epoch 2: val_accuracy improved from 0.84901 to 0.88691, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 901us/step - accuracy: 0.8561 - loss: 0.4099 - val_accuracy: 0.8869 - val_loss: 0.3303\n",
      "Epoch 3/100\n",
      "\u001b[1m72163/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.8838 - loss: 0.3358\n",
      "Epoch 3: val_accuracy improved from 0.88691 to 0.90305, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 853us/step - accuracy: 0.8838 - loss: 0.3358 - val_accuracy: 0.9030 - val_loss: 0.2858\n",
      "Epoch 4/100\n",
      "\u001b[1m72118/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.8994 - loss: 0.2933\n",
      "Epoch 4: val_accuracy improved from 0.90305 to 0.90959, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 863us/step - accuracy: 0.8994 - loss: 0.2933 - val_accuracy: 0.9096 - val_loss: 0.2666\n",
      "Epoch 5/100\n",
      "\u001b[1m72119/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9087 - loss: 0.2686\n",
      "Epoch 5: val_accuracy improved from 0.90959 to 0.91640, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 847us/step - accuracy: 0.9087 - loss: 0.2686 - val_accuracy: 0.9164 - val_loss: 0.2501\n",
      "Epoch 6/100\n",
      "\u001b[1m72105/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.9165 - loss: 0.2467\n",
      "Epoch 6: val_accuracy did not improve from 0.91640\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 839us/step - accuracy: 0.9165 - loss: 0.2467 - val_accuracy: 0.9141 - val_loss: 0.2585\n",
      "Epoch 7/100\n",
      "\u001b[1m72124/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9210 - loss: 0.2339\n",
      "Epoch 7: val_accuracy improved from 0.91640 to 0.91978, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 840us/step - accuracy: 0.9210 - loss: 0.2339 - val_accuracy: 0.9198 - val_loss: 0.2427\n",
      "Epoch 8/100\n",
      "\u001b[1m72133/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.9263 - loss: 0.2205\n",
      "Epoch 8: val_accuracy improved from 0.91978 to 0.92969, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 839us/step - accuracy: 0.9263 - loss: 0.2205 - val_accuracy: 0.9297 - val_loss: 0.2129\n",
      "Epoch 9/100\n",
      "\u001b[1m72167/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9292 - loss: 0.2108\n",
      "Epoch 9: val_accuracy did not improve from 0.92969\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 848us/step - accuracy: 0.9292 - loss: 0.2108 - val_accuracy: 0.9293 - val_loss: 0.2136\n",
      "Epoch 10/100\n",
      "\u001b[1m72130/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9320 - loss: 0.2039\n",
      "Epoch 10: val_accuracy did not improve from 0.92969\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 850us/step - accuracy: 0.9320 - loss: 0.2039 - val_accuracy: 0.9288 - val_loss: 0.2172\n",
      "Epoch 11/100\n",
      "\u001b[1m72149/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9348 - loss: 0.1964\n",
      "Epoch 11: val_accuracy improved from 0.92969 to 0.93469, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 842us/step - accuracy: 0.9348 - loss: 0.1964 - val_accuracy: 0.9347 - val_loss: 0.1989\n",
      "Epoch 12/100\n",
      "\u001b[1m72138/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9378 - loss: 0.1887\n",
      "Epoch 12: val_accuracy improved from 0.93469 to 0.94203, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 848us/step - accuracy: 0.9378 - loss: 0.1887 - val_accuracy: 0.9420 - val_loss: 0.1772\n",
      "Epoch 13/100\n",
      "\u001b[1m72139/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9392 - loss: 0.1847\n",
      "Epoch 13: val_accuracy improved from 0.94203 to 0.94274, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 848us/step - accuracy: 0.9392 - loss: 0.1847 - val_accuracy: 0.9427 - val_loss: 0.1800\n",
      "Epoch 14/100\n",
      "\u001b[1m72152/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9413 - loss: 0.1796\n",
      "Epoch 14: val_accuracy improved from 0.94274 to 0.94409, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 848us/step - accuracy: 0.9413 - loss: 0.1796 - val_accuracy: 0.9441 - val_loss: 0.1744\n",
      "Epoch 15/100\n",
      "\u001b[1m72152/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.9426 - loss: 0.1748\n",
      "Epoch 15: val_accuracy did not improve from 0.94409\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 845us/step - accuracy: 0.9426 - loss: 0.1748 - val_accuracy: 0.9411 - val_loss: 0.1843\n",
      "Epoch 16/100\n",
      "\u001b[1m72121/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.9430 - loss: 0.1739\n",
      "Epoch 16: val_accuracy improved from 0.94409 to 0.94441, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 865us/step - accuracy: 0.9430 - loss: 0.1739 - val_accuracy: 0.9444 - val_loss: 0.1725\n",
      "Epoch 17/100\n",
      "\u001b[1m72129/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9450 - loss: 0.1682\n",
      "Epoch 17: val_accuracy improved from 0.94441 to 0.94735, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 900us/step - accuracy: 0.9450 - loss: 0.1682 - val_accuracy: 0.9474 - val_loss: 0.1648\n",
      "Epoch 18/100\n",
      "\u001b[1m72163/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.9461 - loss: 0.1660\n",
      "Epoch 18: val_accuracy did not improve from 0.94735\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 852us/step - accuracy: 0.9461 - loss: 0.1660 - val_accuracy: 0.9438 - val_loss: 0.1782\n",
      "Epoch 19/100\n",
      "\u001b[1m72105/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9465 - loss: 0.1655\n",
      "Epoch 19: val_accuracy did not improve from 0.94735\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 866us/step - accuracy: 0.9465 - loss: 0.1655 - val_accuracy: 0.9444 - val_loss: 0.1712\n",
      "Epoch 20/100\n",
      "\u001b[1m72132/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.9473 - loss: 0.1626\n",
      "Epoch 20: val_accuracy improved from 0.94735 to 0.95026, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 890us/step - accuracy: 0.9473 - loss: 0.1626 - val_accuracy: 0.9503 - val_loss: 0.1588\n",
      "Epoch 21/100\n",
      "\u001b[1m72112/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9483 - loss: 0.1597\n",
      "Epoch 21: val_accuracy did not improve from 0.95026\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 872us/step - accuracy: 0.9483 - loss: 0.1597 - val_accuracy: 0.9457 - val_loss: 0.1727\n",
      "Epoch 22/100\n",
      "\u001b[1m72150/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9493 - loss: 0.1575\n",
      "Epoch 22: val_accuracy improved from 0.95026 to 0.95333, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 926us/step - accuracy: 0.9493 - loss: 0.1575 - val_accuracy: 0.9533 - val_loss: 0.1470\n",
      "Epoch 23/100\n",
      "\u001b[1m72159/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9504 - loss: 0.1546\n",
      "Epoch 23: val_accuracy improved from 0.95333 to 0.95354, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 848us/step - accuracy: 0.9504 - loss: 0.1546 - val_accuracy: 0.9535 - val_loss: 0.1459\n",
      "Epoch 24/100\n",
      "\u001b[1m72123/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.9507 - loss: 0.1539\n",
      "Epoch 24: val_accuracy did not improve from 0.95354\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 841us/step - accuracy: 0.9507 - loss: 0.1539 - val_accuracy: 0.9500 - val_loss: 0.1594\n",
      "Epoch 25/100\n",
      "\u001b[1m72143/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.9511 - loss: 0.1517\n",
      "Epoch 25: val_accuracy did not improve from 0.95354\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 840us/step - accuracy: 0.9511 - loss: 0.1517 - val_accuracy: 0.9534 - val_loss: 0.1485\n",
      "Epoch 26/100\n",
      "\u001b[1m72155/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9516 - loss: 0.1510\n",
      "Epoch 26: val_accuracy did not improve from 0.95354\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 841us/step - accuracy: 0.9516 - loss: 0.1510 - val_accuracy: 0.9495 - val_loss: 0.1641\n",
      "Epoch 27/100\n",
      "\u001b[1m72158/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9525 - loss: 0.1494\n",
      "Epoch 27: val_accuracy did not improve from 0.95354\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 840us/step - accuracy: 0.9525 - loss: 0.1494 - val_accuracy: 0.9535 - val_loss: 0.1534\n",
      "Epoch 28/100\n",
      "\u001b[1m72165/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.9520 - loss: 0.1497\n",
      "Epoch 28: val_accuracy did not improve from 0.95354\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 841us/step - accuracy: 0.9520 - loss: 0.1497 - val_accuracy: 0.9485 - val_loss: 0.1617\n",
      "Epoch 29/100\n",
      "\u001b[1m72165/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9532 - loss: 0.1462\n",
      "Epoch 29: val_accuracy did not improve from 0.95354\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 842us/step - accuracy: 0.9532 - loss: 0.1462 - val_accuracy: 0.9532 - val_loss: 0.1517\n",
      "Epoch 30/100\n",
      "\u001b[1m72109/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9538 - loss: 0.1456\n",
      "Epoch 30: val_accuracy did not improve from 0.95354\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 840us/step - accuracy: 0.9538 - loss: 0.1456 - val_accuracy: 0.9528 - val_loss: 0.1492\n",
      "Epoch 31/100\n",
      "\u001b[1m72142/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9538 - loss: 0.1454\n",
      "Epoch 31: val_accuracy did not improve from 0.95354\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 845us/step - accuracy: 0.9538 - loss: 0.1454 - val_accuracy: 0.9516 - val_loss: 0.1508\n",
      "Epoch 32/100\n",
      "\u001b[1m72144/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9541 - loss: 0.1445\n",
      "Epoch 32: val_accuracy improved from 0.95354 to 0.95570, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 844us/step - accuracy: 0.9541 - loss: 0.1445 - val_accuracy: 0.9557 - val_loss: 0.1421\n",
      "Epoch 33/100\n",
      "\u001b[1m72151/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9546 - loss: 0.1429\n",
      "Epoch 33: val_accuracy improved from 0.95570 to 0.95576, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 844us/step - accuracy: 0.9546 - loss: 0.1429 - val_accuracy: 0.9558 - val_loss: 0.1384\n",
      "Epoch 34/100\n",
      "\u001b[1m72107/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9549 - loss: 0.1427\n",
      "Epoch 34: val_accuracy did not improve from 0.95576\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 842us/step - accuracy: 0.9549 - loss: 0.1427 - val_accuracy: 0.9551 - val_loss: 0.1441\n",
      "Epoch 35/100\n",
      "\u001b[1m72105/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9553 - loss: 0.1415\n",
      "Epoch 35: val_accuracy did not improve from 0.95576\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 842us/step - accuracy: 0.9553 - loss: 0.1415 - val_accuracy: 0.9487 - val_loss: 0.1607\n",
      "Epoch 36/100\n",
      "\u001b[1m72113/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9552 - loss: 0.1412\n",
      "Epoch 36: val_accuracy did not improve from 0.95576\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 841us/step - accuracy: 0.9552 - loss: 0.1412 - val_accuracy: 0.9540 - val_loss: 0.1467\n",
      "Epoch 37/100\n",
      "\u001b[1m72116/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.9560 - loss: 0.1391\n",
      "Epoch 37: val_accuracy did not improve from 0.95576\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 842us/step - accuracy: 0.9560 - loss: 0.1391 - val_accuracy: 0.9555 - val_loss: 0.1431\n",
      "Epoch 38/100\n",
      "\u001b[1m72134/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.9563 - loss: 0.1379\n",
      "Epoch 38: val_accuracy improved from 0.95576 to 0.95692, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 813us/step - accuracy: 0.9563 - loss: 0.1379 - val_accuracy: 0.9569 - val_loss: 0.1388\n",
      "Epoch 39/100\n",
      "\u001b[1m72137/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9561 - loss: 0.1384\n",
      "Epoch 39: val_accuracy improved from 0.95692 to 0.95986, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809us/step - accuracy: 0.9561 - loss: 0.1384 - val_accuracy: 0.9599 - val_loss: 0.1335\n",
      "Epoch 40/100\n",
      "\u001b[1m72136/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9572 - loss: 0.1363\n",
      "Epoch 40: val_accuracy did not improve from 0.95986\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 808us/step - accuracy: 0.9572 - loss: 0.1363 - val_accuracy: 0.9485 - val_loss: 0.1697\n",
      "Epoch 41/100\n",
      "\u001b[1m72116/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9568 - loss: 0.1368\n",
      "Epoch 41: val_accuracy improved from 0.95986 to 0.96022, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 810us/step - accuracy: 0.9568 - loss: 0.1368 - val_accuracy: 0.9602 - val_loss: 0.1295\n",
      "Epoch 42/100\n",
      "\u001b[1m72134/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9571 - loss: 0.1363\n",
      "Epoch 42: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809us/step - accuracy: 0.9571 - loss: 0.1363 - val_accuracy: 0.9546 - val_loss: 0.1463\n",
      "Epoch 43/100\n",
      "\u001b[1m72161/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9570 - loss: 0.1357\n",
      "Epoch 43: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 810us/step - accuracy: 0.9570 - loss: 0.1357 - val_accuracy: 0.9559 - val_loss: 0.1431\n",
      "Epoch 44/100\n",
      "\u001b[1m72162/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9580 - loss: 0.1347\n",
      "Epoch 44: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809us/step - accuracy: 0.9580 - loss: 0.1347 - val_accuracy: 0.9573 - val_loss: 0.1375\n",
      "Epoch 45/100\n",
      "\u001b[1m72114/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9586 - loss: 0.1329\n",
      "Epoch 45: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 810us/step - accuracy: 0.9586 - loss: 0.1329 - val_accuracy: 0.9547 - val_loss: 0.1511\n",
      "Epoch 46/100\n",
      "\u001b[1m72141/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9583 - loss: 0.1335\n",
      "Epoch 46: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 808us/step - accuracy: 0.9583 - loss: 0.1335 - val_accuracy: 0.9587 - val_loss: 0.1366\n",
      "Epoch 47/100\n",
      "\u001b[1m72144/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9585 - loss: 0.1332\n",
      "Epoch 47: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 808us/step - accuracy: 0.9585 - loss: 0.1332 - val_accuracy: 0.9588 - val_loss: 0.1310\n",
      "Epoch 48/100\n",
      "\u001b[1m72163/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9584 - loss: 0.1321\n",
      "Epoch 48: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 807us/step - accuracy: 0.9584 - loss: 0.1321 - val_accuracy: 0.9473 - val_loss: 0.1727\n",
      "Epoch 49/100\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9589 - loss: 0.1318\n",
      "Epoch 49: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 807us/step - accuracy: 0.9589 - loss: 0.1318 - val_accuracy: 0.9581 - val_loss: 0.1372\n",
      "Epoch 50/100\n",
      "\u001b[1m72104/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9588 - loss: 0.1321\n",
      "Epoch 50: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 808us/step - accuracy: 0.9588 - loss: 0.1321 - val_accuracy: 0.9595 - val_loss: 0.1320\n",
      "Epoch 51/100\n",
      "\u001b[1m72138/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9589 - loss: 0.1328\n",
      "Epoch 51: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809us/step - accuracy: 0.9589 - loss: 0.1328 - val_accuracy: 0.9443 - val_loss: 0.1864\n",
      "Epoch 52/100\n",
      "\u001b[1m72118/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9588 - loss: 0.1325\n",
      "Epoch 52: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809us/step - accuracy: 0.9588 - loss: 0.1325 - val_accuracy: 0.9537 - val_loss: 0.1541\n",
      "Epoch 53/100\n",
      "\u001b[1m72129/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9591 - loss: 0.1308\n",
      "Epoch 53: val_accuracy did not improve from 0.96022\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809us/step - accuracy: 0.9591 - loss: 0.1308 - val_accuracy: 0.9587 - val_loss: 0.1379\n",
      "Epoch 54/100\n",
      "\u001b[1m72166/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9596 - loss: 0.1301\n",
      "Epoch 54: val_accuracy improved from 0.96022 to 0.96073, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809us/step - accuracy: 0.9596 - loss: 0.1301 - val_accuracy: 0.9607 - val_loss: 0.1321\n",
      "Epoch 55/100\n",
      "\u001b[1m72109/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9601 - loss: 0.1295\n",
      "Epoch 55: val_accuracy improved from 0.96073 to 0.96468, saving model to weights.best.keras\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 811us/step - accuracy: 0.9601 - loss: 0.1295 - val_accuracy: 0.9647 - val_loss: 0.1169\n",
      "Epoch 56/100\n",
      "\u001b[1m72123/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9597 - loss: 0.1305\n",
      "Epoch 56: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809us/step - accuracy: 0.9597 - loss: 0.1305 - val_accuracy: 0.9599 - val_loss: 0.1306\n",
      "Epoch 57/100\n",
      "\u001b[1m72137/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9599 - loss: 0.1283\n",
      "Epoch 57: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 808us/step - accuracy: 0.9599 - loss: 0.1283 - val_accuracy: 0.9556 - val_loss: 0.1522\n",
      "Epoch 58/100\n",
      "\u001b[1m72119/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9606 - loss: 0.1276\n",
      "Epoch 58: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 810us/step - accuracy: 0.9606 - loss: 0.1276 - val_accuracy: 0.9602 - val_loss: 0.1321\n",
      "Epoch 59/100\n",
      "\u001b[1m72139/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9608 - loss: 0.1277\n",
      "Epoch 59: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809us/step - accuracy: 0.9608 - loss: 0.1277 - val_accuracy: 0.9574 - val_loss: 0.1418\n",
      "Epoch 60/100\n",
      "\u001b[1m72143/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.9607 - loss: 0.1283\n",
      "Epoch 60: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 836us/step - accuracy: 0.9607 - loss: 0.1283 - val_accuracy: 0.9572 - val_loss: 0.1453\n",
      "Epoch 61/100\n",
      "\u001b[1m72112/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9610 - loss: 0.1260\n",
      "Epoch 61: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 867us/step - accuracy: 0.9610 - loss: 0.1260 - val_accuracy: 0.9554 - val_loss: 0.1444\n",
      "Epoch 62/100\n",
      "\u001b[1m72108/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.9606 - loss: 0.1264\n",
      "Epoch 62: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 855us/step - accuracy: 0.9606 - loss: 0.1264 - val_accuracy: 0.9610 - val_loss: 0.1319\n",
      "Epoch 63/100\n",
      "\u001b[1m72115/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.9614 - loss: 0.1259\n",
      "Epoch 63: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 857us/step - accuracy: 0.9614 - loss: 0.1259 - val_accuracy: 0.9616 - val_loss: 0.1272\n",
      "Epoch 64/100\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.9610 - loss: 0.1273\n",
      "Epoch 64: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 856us/step - accuracy: 0.9610 - loss: 0.1273 - val_accuracy: 0.9613 - val_loss: 0.1291\n",
      "Epoch 65/100\n",
      "\u001b[1m72109/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.9615 - loss: 0.1260\n",
      "Epoch 65: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 857us/step - accuracy: 0.9615 - loss: 0.1260 - val_accuracy: 0.9640 - val_loss: 0.1222\n",
      "Epoch 66/100\n",
      "\u001b[1m72127/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.9615 - loss: 0.1265\n",
      "Epoch 66: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 858us/step - accuracy: 0.9615 - loss: 0.1265 - val_accuracy: 0.9567 - val_loss: 0.1502\n",
      "Epoch 67/100\n",
      "\u001b[1m72121/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.9611 - loss: 0.1274\n",
      "Epoch 67: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 857us/step - accuracy: 0.9611 - loss: 0.1274 - val_accuracy: 0.9584 - val_loss: 0.1384\n",
      "Epoch 68/100\n",
      "\u001b[1m72116/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9615 - loss: 0.1256\n",
      "Epoch 68: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 858us/step - accuracy: 0.9615 - loss: 0.1256 - val_accuracy: 0.9624 - val_loss: 0.1312\n",
      "Epoch 69/100\n",
      "\u001b[1m72110/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9621 - loss: 0.1240\n",
      "Epoch 69: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 858us/step - accuracy: 0.9621 - loss: 0.1240 - val_accuracy: 0.9588 - val_loss: 0.1390\n",
      "Epoch 70/100\n",
      "\u001b[1m72145/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9618 - loss: 0.1266\n",
      "Epoch 70: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 859us/step - accuracy: 0.9618 - loss: 0.1266 - val_accuracy: 0.9602 - val_loss: 0.1433\n",
      "Epoch 71/100\n",
      "\u001b[1m72130/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9619 - loss: 0.1250\n",
      "Epoch 71: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 859us/step - accuracy: 0.9619 - loss: 0.1250 - val_accuracy: 0.9639 - val_loss: 0.1235\n",
      "Epoch 72/100\n",
      "\u001b[1m72102/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9617 - loss: 0.1264\n",
      "Epoch 72: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 859us/step - accuracy: 0.9617 - loss: 0.1264 - val_accuracy: 0.9603 - val_loss: 0.1305\n",
      "Epoch 73/100\n",
      "\u001b[1m72157/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.9626 - loss: 0.1236\n",
      "Epoch 73: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 861us/step - accuracy: 0.9626 - loss: 0.1236 - val_accuracy: 0.9527 - val_loss: 0.1562\n",
      "Epoch 74/100\n",
      "\u001b[1m72107/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.9623 - loss: 0.1237\n",
      "Epoch 74: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 861us/step - accuracy: 0.9623 - loss: 0.1237 - val_accuracy: 0.9489 - val_loss: 0.1769\n",
      "Epoch 75/100\n",
      "\u001b[1m72118/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9620 - loss: 0.1263\n",
      "Epoch 75: val_accuracy did not improve from 0.96468\n",
      "\u001b[1m72168/72168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 862us/step - accuracy: 0.9620 - loss: 0.1263 - val_accuracy: 0.9543 - val_loss: 0.1524\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"weights.best.keras\"\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                              patience=20)\n",
    "\n",
    "history = model.fit(train_keypoints, train_labels,\n",
    "                    epochs=100,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(test_keypoints, test_labels),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_keypoints, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Utility\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "keypoints = np.array(annotations[0]['pose2'])\n",
    "\n",
    "keypoints = [[0] * 2] * num_keypoints\n",
    "keypoints += [keypoint[:2] for keypoint in keypoints]\n",
    "\n",
    "keypoints = np.array(keypoints).astype(np.float32).reshape(num_keypoints * num_players * 2)\n",
    "\n",
    "print(keypoints.shape)\n",
    "\n",
    "max_x = max(keypoints)\n",
    "normalized_keypoints = keypoints / max_x\n",
    "\n",
    "prediction = model.predict(normalized_keypoints.reshape(1, num_keypoints * 2 * num_players))\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "max_index = np.argmax(prediction[0])\n",
    "\n",
    "for label, index in labels.items():\n",
    "    if index == max_index:\n",
    "        print(label)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for each label\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "n = len(test_keypoints)\n",
    "\n",
    "print(n)\n",
    "\n",
    "for i in range(0, n):\n",
    "    test = np.array([test_keypoints[i]])\n",
    "\n",
    "    prediction = model.predict(test)\n",
    "    \n",
    "    correct_label = np.argmax(test_labels[i])\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    label_name = list(labels.keys())[predicted_label]\n",
    "    \n",
    "    if predicted_label == correct_label:\n",
    "        if label_name in test_dict:\n",
    "            test_dict[label_name][\"correct\"] += 1\n",
    "        else:\n",
    "            test_dict[label_name] = {\"correct\": 1, \"incorrect\": 0}\n",
    "    else:\n",
    "        if label_name in test_dict:\n",
    "            test_dict[label_name][\"incorrect\"] += 1\n",
    "        else:\n",
    "            test_dict[label_name] = {\"correct\": 0, \"incorrect\": 1}\n",
    "    \n",
    "for key in test_dict:\n",
    "    correct = test_dict[key][\"correct\"]\n",
    "    incorrect = test_dict[key][\"incorrect\"]\n",
    "    \n",
    "    print(f\"Accuracy for {key}: {correct / (correct + incorrect)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
