{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 640\n",
    "\n",
    "labels = {'standing': 0, 'takedown': 1, 'open_guard': 2, 'half_guard': 3, 'closed_guard': 4, '5050_guard': 5, 'side_control': 6, 'mount': 7, 'back': 8, 'turtle': 9}\n",
    "body_parts = [\"nose\", \"left eye\", \"right eye\", \"left ear\", \"right ear\", \"left shoulder\", \"right shoulder\", \"left elbow\", \"right elbow\", \"left wrist\", \"right wrist\", \"left hip\", \"right hip\", \"left knee\", \"right knee\", \"left ankle\", \"right ankle\"]\n",
    "num_labels = len(labels)\n",
    "num_keypoints = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando modelo coco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "pose_model = YOLO('../../coco_model/yolov8n-pose.pt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "def draw_image_with_keypoints(image_path, keypoints):\n",
    "    image = cv.imread(image_path)\n",
    "\n",
    "    image = cv.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "    for i in range(num_keypoints):\n",
    "        x = int(keypoints[i][0].item())\n",
    "        y = int(keypoints[i][1].item())\n",
    "        cv.circle(image, (x, y), 5, (0, 255, 0), -1)\n",
    "        cv.putText(image, body_parts[i], (x, y), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "    cv.imshow('image', image)\n",
    "    cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando modelo pose BJJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"jiu_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import numpy as np\n",
    "\n",
    "def get_keypoints(image_path):\n",
    "    predictions = pose_model(image_path)[0]\n",
    "\n",
    "    keypoints = predictions[0].keypoints\n",
    "    \n",
    "    keypoints_tensor = keypoints.data\n",
    "    \n",
    "    keypoints = keypoints_tensor.numpy()\n",
    "    \n",
    "    return keypoints\n",
    "\n",
    "def pose_prediction(keypoints):\n",
    "    keypoints = np.array(keypoints)\n",
    "    \n",
    "    keypoints = keypoints.reshape(1, 51)\n",
    "    \n",
    "    prediction = model.predict(keypoints)\n",
    "    \n",
    "    max_index = np.argmax(prediction)\n",
    "    \n",
    "    return max_index   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação em imagem única"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\guilh\\Documents\\bjj_ia\\versions\\v1\\..\\..\\tmp\\temp.jpg: 640x640 1 person, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted Label:  side_control\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_path = '../../test_images/back01.jpeg'\n",
    "\n",
    "temp_path = '../../tmp'\n",
    "\n",
    "# resize the image\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "image = cv.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "cv.imwrite(temp_path + '/temp.jpg', image)\n",
    "\n",
    "keypoints = get_keypoints(temp_path + '/temp.jpg')\n",
    "\n",
    "draw_image_with_keypoints(image_path, keypoints[0])\n",
    "\n",
    "label_index = pose_prediction(keypoints)\n",
    "\n",
    "print(\"Predicted Label: \", list(labels.keys())[label_index])\n",
    "\n",
    "os.remove(temp_path + '/temp.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação em vídeo em tempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # type: ignore\n",
    "\n",
    "cap = cv2.VideoCapture(\"../../test_videos/video.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    \n",
    "    keypoints, img = get_keypoints(frame)\n",
    "    label_index = pose_prediction(keypoints)\n",
    "    \n",
    "    print(\"Predicted Label: \", list(labels.keys())[label_index])\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
